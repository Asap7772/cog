2021-06-10 02:31:54.315075 PDT | [test_2021_06_10_02_30_26_0000--s-0] Epoch 0 finished
----------------------------  ---------------
replay_buffer/top             16295
trainer/Num Policy Updates        1
trainer/Policy Loss              16.078
trainer/Log Pis Mean             -2.70578
trainer/Log Pis Std               0.446953
trainer/Log Pis Max              -1.47794
trainer/Log Pis Min              -4.33855
trainer/Policy mu Mean            0.00035243
trainer/Policy mu Std             0.00134794
trainer/Policy mu Max             0.00263757
trainer/Policy mu Min            -0.00066544
trainer/Policy log std Mean       0.000355357
trainer/Policy log std Std        0.000735897
trainer/Policy log std Max        0.00105105
trainer/Policy log std Min       -0.000742929
exploration/num steps total       0
exploration/num paths total       0
evaluation/num steps total        5
evaluation/num paths total        5
evaluation/path length Mean       1
evaluation/path length Std        0
evaluation/path length Max        1
evaluation/path length Min        1
evaluation/Rewards Mean           0
evaluation/Rewards Std            0
evaluation/Rewards Max            0
evaluation/Rewards Min            0
evaluation/Returns Mean           0
evaluation/Returns Std            0
evaluation/Returns Max            0
evaluation/Returns Min            0
evaluation/Actions Mean           0.000352429
evaluation/Actions Std            0.00134794
evaluation/Actions Max            0.00263756
evaluation/Actions Min           -0.00066544
evaluation/Num Paths              5
evaluation/Average Returns        0
time/evaluation sampling (s)      0.0203703
time/logging (s)                  0.00372671
time/saving (s)                   0.000298933
time/training (s)                36.6368
time/epoch (s)                   36.6612
time/total (s)                   89.9049
Epoch                             0
----------------------------  ---------------
Traceback (most recent call last):
  File "/nfs/kun1/users/asap7772/cog/examples/bc_image_real.py", line 333, in <module>
    experiment(variant)
  File "/nfs/kun1/users/asap7772/cog/examples/bc_image_real.py", line 147, in experiment
    algorithm.train()
  File "/nfs/kun1/users/asap7772/cog/rlkit/core/rl_algorithm.py", line 47, in train
    self._train()
  File "/nfs/kun1/users/asap7772/cog/rlkit/core/batch_rl_algorithm.py", line 176, in _train
    self.trainer.train(train_data)
  File "/nfs/kun1/users/asap7772/cog/rlkit/torch/torch_rl_algorithm.py", line 40, in train
    self.train_from_torch(batch)
  File "/nfs/kun1/users/asap7772/cog/rlkit/torch/sac/bc.py", line 67, in train_from_torch
    obs, reparameterize=True, return_log_prob=True,
  File "/home/asap7772/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/nfs/kun1/users/asap7772/cog/rlkit/torch/sac/policies.py", line 133, in forward
    h = self.hidden_activation(fc(h))
  File "/home/asap7772/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/asap7772/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/asap7772/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1370, in linear
    ret = torch.addmm(bias, input, weight.t())
KeyboardInterrupt
