wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.10.31
    framework: torch
    is_jupyter_run: true
    is_kaggle_kernel: false
    python_version: 3.6.10
    t:
      1:
      - 1
      4: 3.6.10
      5: 0.10.31
      8:
      - 1
      - 5
algorithm:
  desc: null
  value: BC
algorithm_kwargs:
  desc: null
  value:
    batch_size: 256
    max_path_length: 1
    min_num_steps_before_training: 1000
    num_epochs: 3000
    num_eval_steps_per_epoch: 5
    num_expl_steps_per_train_loop: 5
    num_trains_per_train_loop: 1000
bin:
  desc: null
  value: false
buffer:
  desc: null
  value: 5
chaining:
  desc: null
  value: false
cnn_params:
  desc: null
  value:
    added_fc_input_size: 0
    hidden_sizes:
    - 1024
    - 512
    image_augmentation: true
    image_augmentation_padding: 4
    input_channels: 3
    input_height: 64
    input_width: 64
    kernel_sizes:
    - 3
    - 3
    - 3
    n_channels:
    - 16
    - 16
    - 16
    output_size: 256
    paddings:
    - 1
    - 1
    - 1
    pool_paddings:
    - 0
    - 0
    - 0
    pool_sizes:
    - 2
    - 2
    - 1
    pool_strides:
    - 2
    - 2
    - 1
    pool_type: max2d
    strides:
    - 1
    - 1
    - 1
deeper_net:
  desc: null
  value: false
dist_diff:
  desc: null
  value: false
dump_video_kwargs:
  desc: null
  value:
    imsize: 48
    save_video_period: 1
duplicate:
  desc: null
  value: false
eval_multiview:
  desc: null
  value: single
image_shape:
  desc: null
  value:
  - 64
  - 64
  - 3
imgstate:
  desc: null
  value: false
log_dir:
  desc: null
  value: /nfs/kun1/users/asap7772/cog/rlkit/../data/real-pickplace-bc-resize/real_pickplace_bc_resize_2021_06_16_16_59_22_0000--s-0
mixture:
  desc: null
  value: false
multi_bin:
  desc: null
  value: false
num_traj:
  desc: null
  value: 0
p:
  desc: null
  value: 0.2
seed:
  desc: null
  value: 10
segment_type:
  desc: null
  value: fixed_other
small_image:
  desc: null
  value: false
state_dim:
  desc: null
  value: 3
trainer_kwargs:
  desc: null
  value:
    deterministic_backup: true
    discount: 0.99
    lagrange_thresh: 5.0
    max_q_backup: false
    min_q_version: 3
    min_q_weight: 1.0
    num_qs: 2
    num_random: 1
    policy_eval_start: 10000
    policy_lr: 0.0001
    qf_lr: 0.0003
    reward_scale: 1
    soft_target_tau: 0.005
    temp: 1.0
    use_automatic_entropy_tuning: true
    with_lagrange: false
transfer:
  desc: null
  value: false
transfer_multiview:
  desc: null
  value: false
version:
  desc: null
  value: normal
vqvae_enc:
  desc: null
  value: false
