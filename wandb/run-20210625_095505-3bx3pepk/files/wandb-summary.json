{"trainer/QF1 Loss": 319.95562744140625, "trainer/min QF1 Loss": -6.0419921875, "trainer/Std QF1 values": 15.160049438476562, "trainer/QF1 in-distribution values Mean": -173.19091796875, "trainer/QF1 in-distribution values Std": 77.82481384277344, "trainer/QF1 in-distribution values Max": -79.8282699584961, "trainer/QF1 in-distribution values Min": -374.8822937011719, "trainer/QF1 random values Mean": -186.29283142089844, "trainer/QF1 random values Std": 74.71257781982422, "trainer/QF1 random values Max": -95.12528991699219, "trainer/QF1 random values Min": -359.6418762207031, "trainer/QF1 next_actions values Mean": -173.5264434814453, "trainer/QF1 next_actions values Std": 79.425048828125, "trainer/QF1 next_actions values Max": -77.38945770263672, "trainer/QF1 next_actions values Min": -357.9805603027344, "trainer/actions Mean": -0.0390625, "trainer/actions Std": 0.5918927788734436, "trainer/actions Max": 1.0, "trainer/actions Min": -1.0, "trainer/rewards Mean": 2.3046875, "trainer/rewards Std": 4.211328983306885, "trainer/rewards Max": 10.0, "trainer/rewards Min": 0.0, "trainer/Num Q Updates": 6001, "trainer/Num Policy Updates": 6001, "trainer/Policy Loss": 171.77764892578125, "trainer/Q1 Predictions Mean": -156.29421997070312, "trainer/Q1 Predictions Std": 74.83129119873047, "trainer/Q1 Predictions Max": -76.97898864746094, "trainer/Q1 Predictions Min": -322.6297607421875, "trainer/Q Targets Mean": -156.27407836914062, "trainer/Q Targets Std": 78.6280517578125, "trainer/Q Targets Max": -57.622047424316406, "trainer/Q Targets Min": -344.0702209472656, "trainer/Log Pis Mean": 0.5117764472961426, "trainer/Log Pis Std": 3.5154850482940674, "trainer/Log Pis Max": 8.265007019042969, "trainer/Log Pis Min": -7.324743270874023, "trainer/Policy mu Mean": -0.03867940604686737, "trainer/Policy mu Std": 0.1401650607585907, "trainer/Policy mu Max": 0.15605293214321136, "trainer/Policy mu Min": -0.3028906285762787, "trainer/Policy log std Mean": 0.06343639642000198, "trainer/Policy log std Std": 0.8169402480125427, "trainer/Policy log std Max": 1.577968955039978, "trainer/Policy log std Min": -1.0103965997695923, "trainer/QF1 DR3 Loss": 0.003329214407131076, "trainer/Alpha": 0.5603036880493164, "trainer/Alpha Loss": -2.020310878753662, "_runtime": 3588, "_timestamp": 1624643695, "_step": 6}